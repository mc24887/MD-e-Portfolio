<!doctype html> 
<html lang="en"><head>
<meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>Research Methods & Professional Practice – e-Portfolio</title>
<link rel="stylesheet" href="../../assets/style.css">
</head><body>
  <div class="header">
    <div class="nav">
      <div class="brand"><a href="../../index.html" style="color:#fff;text-decoration:none;">&larr; Home</a></div>
      <div class="small">Research Methods &amp; Professional Practice <span class="badge progress">In Progress</span></div>
    </div>
  </div>

  <div class="container page">

    <div class="section"><h2>Module Overview</h2>
      <p class="small">
        This module develops skills in research design, ethical practice, and professional reflection within the computing discipline. 
        Progress so far includes ethical analysis, structured discussion, literature review preparation, and applied research methods activities.
      </p>
    </div>

    <div class="section"><h2>Key Activities (to date)</h2>

      <!-- Existing activities (kept) -->
      <details class="small" open>
        <summary><strong>Initial Forum Post – ACM Case Study</strong></summary>
        <p class="small">
          Analysed the ACM case study <em>“Inadequate Security Measures”</em> where a developer deployed software 
          with known vulnerabilities to meet a deadline, breaching ACM Principles 2.9 (secure systems) and 1.2 (avoid harm).  
          Compared with BCS Code, obligations to act in the public interest and maintain integrity.  
          Highlighted potential breaches of the UK Data Protection Act 2018.  
          Reflected on the importance of risk escalation, documenting known issues, and resisting commercial pressure to compromise security.
        </p>
      </details>

      <details class="small">
        <summary><strong>Reflective Activity 1 – Ethics in AI</strong></summary>
        <p class="small">
          Reviewed Correa et&nbsp;al. (2023) on global AI governance guidelines and Deckard (2023) on AI ethics in practice.  
          Reflected on the challenges of achieving consensus across stakeholders and proposed practitioner-focused guidance 
          for integrating AI ethics into secure software development.
        </p>
      </details>

      <details class="small">
        <summary><strong>Literature Review Preparation</strong></summary>
        <p class="small">
          Selected provisional topic: how AI ethics frameworks influence secure software engineering practices.  
          Drafted inclusion/exclusion criteria and identified databases (IEEE Xplore, ACM DL, Scopus) for search.  
          Work is ongoing towards a structured outline for formative feedback.
        </p>
      </details>

      <!-- NEW: Unit 5 activities (added without removing anything) -->
      <details class="small">
        <summary><strong>Unit 5 – Data Collection Update</strong></summary>
        <p class="small">
          For my project on <em>Generative AI risks in software security and email workflows</em>, I will use a <strong>mixed-methods</strong> approach:
        </p>
        <ul class="compact small">
          <li><strong>Survey (quantitative):</strong> capture prevalence and perceptions of AI-assisted phishing, BEC and prompt-injection threats across IT/security practitioners. Analysis: descriptive stats (frequencies, cross-tabs) and hypothesis tests where appropriate.</li>
          <li><strong>Semi-structured interviews (qualitative):</strong> security leads/engineers to explore governance decisions, mitigation strategies, and ethical concerns. Analysis: thematic coding (e.g., NVivo) to identify patterns and tensions (usability vs control strength).</li>
        </ul>
        <p class="small">
          Instruments will be pilot-tested; participation information and consent will reflect <em>purpose limitation</em> and <em>data minimisation</em>. 
          This design links large-scale trends (survey) to in-depth reasoning (interviews), directly answering my research questions.
        </p>
      </details>

      <details class="small">
        <summary><strong>Unit 5 – Wiki Activity: Questionnaire Design</strong></summary>
        <ul class="compact small">
          <li>Use clear, unambiguous wording; avoid leading or double-barrelled questions; one construct per item.</li>
          <li>Ensure every item maps directly to a research objective; remove “nice-to-know” items.</li>
          <li>Balance open and closed questions to capture both measurable and exploratory insights; include a <em>Prefer not to say</em> option where appropriate.</li>
          <li>Apply skip/branch logic carefully; <strong>pilot</strong> to test comprehension, timing, and reliability before deployment.</li>
          <li>Embed ethics: transparent purpose, proportionate data fields, consent, retention/deletion plan.</li>
        </ul>
        <p class="small">
          These principles improve validity, reduce bias, and protect autonomy, aligning with ACM/BCS professional codes.
        </p>
      </details>

      <details class="small">
        <summary><strong>Unit 5 – Reflective Activity 2: Inappropriate Use of Surveys</strong></summary>
        <p class="small">
          The <em>Cambridge Analytica</em> case (Confessore, 2018) showed how Facebook quizzes harvested personal and network data at scale and repurposed it for political micro-targeting. 
          This violated meaningful consent and <em>purpose limitation</em>, undermining trust in digital platforms.
        </p>
        <ul class="compact small">
          <li><strong>Ethical:</strong> Deception/lack of informed consent; conflicts with ACM 1.2 (avoid harm).</li>
          <li><strong>Social:</strong> Manipulation of public discourse; erosion of trust; disproportionate impact on vulnerable groups.</li>
          <li><strong>Legal:</strong> Likely breaches of GDPR and the Data Protection Act 2018 (lawful basis, transparency, minimisation, rights).</li>
          <li><strong>Professional:</strong> Contravenes BCS duties (public interest, integrity, privacy) and weakens accountability.</li>
        </ul>
        <p class="small">
          Similar risks appear in mobile quiz apps requesting excessive permissions sold to advertisers, and health surveys reused by insurers to influence premiums. 
          For my study, I will apply <strong>transparency, proportionality, and explicit consent</strong> with defined retention/deletion schedules; any secondary use will require fresh consent.
        </p>
      </details>
      <!-- END Unit 5 additions -->

      <!-- Existing later activities (kept) -->
      <details class="small">
        <summary><strong>Unit 7–8: Hypothesis Testing &amp; Summary Measures Worksheets</strong></summary>
        <p class="small">
          Completed worksheets on hypothesis testing and summary measures (Excel/LibreOffice).  
          Interpreted results based on statistical questions, noting implications for research validity and inference.  
          These worksheets form a compulsory e-Portfolio component and will be included in the final submission.  
        </p>
      </details>

      <details class="small">
        <summary><strong>Unit 7–8: Research Proposal Outline</strong></summary>
        <p class="small">
          Drafted a proposal outline including research problem, aims, proposed methodology, and ethical considerations.  
          Submitted for formative feedback, which will guide the Unit 10 research proposal presentation.  
        </p>
      </details>

      <details class="small">
        <summary><strong>Unit 8–9: Statistical Worksheets</strong></summary>
        <p class="small">
          Completed statistical worksheets (charts, inference, summary measures) and provided interpretation of outputs.  
          Worksheets demonstrate practical application of hypothesis testing to simulated datasets.  
          These will be collated and submitted in the final e-Portfolio in Unit 12.  
        </p>
      </details>

    </div>

    <div class="section"><h2>Reflection</h2>
      <p class="small">
        The early stages reinforced the link between ethical codes and practical decisions in project contexts. 
        Applying frameworks like ACM and BCS has shown how they can directly inform release decisions, risk handling, and governance.
        Unit 5 added practical depth: effective data collection depends on <em>method choice</em>, <em>instrument design</em>, and <em>ethics</em>. 
        The statistical activities in Units 7–9 developed confidence in analysing data, interpreting hypothesis tests, and linking results 
        to real research problems. Moving forward, the focus will be on producing a literature review that is methodologically sound and on 
        preparing a viable, ethics-aware research proposal.
      </p>
    </div>

    <div class="section"><h2>Skills Developed (so far)</h2>
      <ul class="compact small">
        <li>Applying professional codes (ACM/BCS) to case scenarios</li>
        <li>Structuring reflective writing for academic purposes</li>
        <li>Designing a reproducible literature search</li>
        <li>Framing research questions within ethical constraints</li>
        <li>Designing valid, unbiased questionnaires and interview guides</li>
        <li>Choosing suitable mixed-methods (surveys + interviews) for the project</li>
        <li>Conducting hypothesis testing and interpreting results</li>
        <li>Using Excel/LibreOffice for statistical analysis and visualisation</li>
      </ul>
    </div>

    <div class="section"><h2>References</h2>
      <p class="small">
        ACM (2018) <em>Code of Ethics and Professional Conduct</em>. Available at: https://www.acm.org/code-of-ethics.<br>
        BCS (2021) <em>Code of Conduct</em>. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/.<br>
        Confessore, N. (2018) ‘Cambridge Analytica and Facebook: The scandal and the fallout’, <em>New York Times</em>.<br>
        ICO (2018) <em>Investigation into the use of data analytics in political campaigns</em>. Information Commissioner’s Office.<br>
        Correa, N. et&nbsp;al. (2023) ‘Worldwide AI ethics: a review of 200 guidelines and recommendations for AI governance’.<br>
        Deckard, R. (2023) <em>What are Ethics in AI</em>.<br>
        Legislation.gov.uk (2018) <em>Data Protection Act 2018</em>. Available at: https://www.legislation.gov.uk/ukpga/2018/12/contents.<br>
        OWASP (2023) <em>Secure Software Development Lifecycle (SSDLC)</em>. Available at: https://owasp.org/www-project-secure-software-development-lifecycle/.
      </p>
    </div>

    <!-- Feedback area unchanged -->
    <div class="section">
      <h2>Feedback</h2>
      <p class="small">Constructive feedback is welcome. Use the form or raise a GitHub issue.</p>
      <form action="mailto:mc24887@essex.ac.uk" method="post" enctype="text/plain" class="small">
        <label>Name<br><input type="text" name="name" required></label><br><br>
        <label>Email<br><input type="email" name="email" required></label><br><br>
        <label>Feedback<br><textarea name="message" rows="4" required></textarea></label><br><br>
        <button type="submit">Send feedback</button>
        <a class="small" style="margin-left:10px" href="https://github.com/mc24887/MD-e-Portfolio/issues/new" target="_blank">Suggest via GitHub Issue</a>
      </form>
      <p class="small">Alternatively, email: <kbd>mc24887@essex.ac.uk</kbd></p>
    </div>

  </div>

  <div class="footer">© 2025–2026 mc24887 | MSc Cyber Security</div>
</body></html>
